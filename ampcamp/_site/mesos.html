<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Mesos - Cluster & Framework Mgmt</title>
        <meta name="description" content="">

        <!--<link rel="stylesheet" href="css/vendor/bootstrap/bootstrap.min.css">-->
        <link rel="stylesheet" href="css/vendor/bootstrap/bootstrap.css">
        <meta name="viewport" content="width=device-width">
        <!--<link rel="stylesheet" href="css/vendor/bootstrap/bootstrap-responsive.min.css">-->
        <link rel="stylesheet" href="css/vendor/bootstrap/bootstrap-responsive.css">
        <link rel="stylesheet" href="css/vendor/font-awesome.min.css">
        <!--[if IE 7]>
        <link rel="stylesheet" href="assets/css/vendorfont-awesome-ie7.min.css">
        <![endif]-->
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

         <!-- prettify js and CSS, used for code highlighting -->
        <link rel="stylesheet" href="css/vendor/prettify/prettify.css" type="text/css" />
        <script src="js/vendor/prettify/prettify.js" type="text/javascript"></script>
        <script src="js/vendor/prettify/lang-scala.js" type="text/javascript"></script>
        <script src="js/vendor/prettify/lang-sql.js" type="text/javascript"></script>
        <script type="text/javascript">

          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-33205054-1']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();

        </script>

    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="http://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="bar topbar">
            
<a class="btn page-nav" disabled="disable" style="float:left">

  <i class="icon-arrow-left icon-2x"></i>
</a>

            
<a class="btn page-nav" disabled="disable" style="float:right" href="#">

  <i class="icon-arrow-right icon-2x"></i>
</a>

            <a href="http://ampcamp.berkeley.edu/ampcamp3-exercises/" id="ampcamp-logo"></a>
            <!--<img src="img/amplab-small.png" alt="AMP Camp Logo" width="150" id="amplab-logo"/>-->
            <div id="topbar-middle">
                <div class="site-title">AMP Camp 3 Exercises Dry-Run</div>
                <div class="btn-group">
                    <div class="btn btn-large dropdown-toggle" data-toggle="dropdown">
                        Mesos - Cluster & Framework Mgmt &nbsp; <i class="icon-list-ul icon"></i>
                    </div>
                    <ul class="dropdown-menu" role="menu" aria-labelledby="dropdownMenu">


  <li>
    
      
    
    <a href="/index.html">Introduction</a>
  </li>

  <li>
    
      
    
    <a href="/logging-into-the-cluster.html">Logging into the Cluster</a>
  </li>

  <li>
    
      
    
    <a href="/overview-of-the-exercises.html">Overview Of The Exercises</a>
  </li>

  <li>
    
      
    
    <a href="/introduction-to-the-scala-shell.html">Introduction to the Scala Shell</a>
  </li>

  <li>
    
      
      
    
    <a href="/data-exploration-using-spark.html">  1. Data Exploration Using Spark</a>
  </li>

  <li>
    
      
      
    
    <a href="/data-exploration-using-shark.html">  2. Data Exploration Using Shark</a>
  </li>

  <li>
    
      
      
    
    <a href="/realtime-processing-with-spark-streaming.html">  3. Stream Processing w/ Spark Streaming</a>
  </li>

  <li>
    
      
      
    
    <a href="/blinkdb.html">  4. Data Exploration Using BlinkDB</a>
  </li>

  <li>
    
      
      
    
    <a href="/mli-document-categorization.html">  5. Machine Learning With MLI</a>
  </li>

  <li>
    
      
      
    
    <a href="/mesos.html">  6. Mesos - Cluster & Framework Mgmt</a>
  </li>

  <li>
    
      
    
    <a href="/where-to-go-from-here.html">Where to Go From Here</a>
  </li>

</ul>
                </div>
            </div>
        </div><!--topbar-->
        <div class="container" id="content">
            
            <p>Apache Mesos is a cluster manager that makes building and running
distributed systems, or <em>frameworks</em>, easy and efficient. Using Mesos
you can simultaneously run Apache Hadoop, Apache Spark, Apache Storm,k
and many other applications on a dynamically shared pool of resources
(machines).</p>

<p>Mesos itself is a distributed system made up of <em>masters</em> and
<em>slaves</em>. You should have been given <code>master_node_hostname</code> at the
beginning of this training, or you might have <a href="launching-a-spark-shark-cluster-on-ec2.html">launched your own
cluster</a> and made a note
of it then.</p>

<p>Let&#8217;s start by logging into <code>master_node_hostname</code>:</p>

<pre class="prettyprint lang-bsh">
$ ssh -i /path/to/ampcamp3-all.pem root@master_node_hostname</pre>

<h3 id="command-line-flags">Command Line Flags</h3>

<p>The master and slaves can be configured using command line
flags. There is not a configuration file for Mesos, but any command
line flag can be passed via an environment variable prefixed with
<code>MESOS_</code>.</p>

<ol>
  <li>
    <p>Use <code>--help</code> to see the available flags:</p>

    <pre class="prettyprint lang-bsh">
$ mesos-master --help</pre>

    <div class="solution">
      <pre>
Usage: mesos-master [...]

Supported options:
  --allocation_interval=VALUE     Amount of time to wait between performing
                                   (batch) allocations (e.g., 500ms, 1sec, etc) (default: 1secs)
  --cluster=VALUE                 Human readable name for the cluster,
                                  displayed in the webui
  --framework_sorter=VALUE        Policy to use for allocating resources
                                  between a given user's frameworks. Options
                                  are the same as for user_allocator (default: drf)
  --[no-]help                     Prints this help message (default: false)
  --ip=VALUE                      IP address to listen on
  --log_dir=VALUE                 Location to put log files (no default, nothing
                                  is written to disk unless specified;
                                  does not affect logging to stderr)
  --logbufsecs=VALUE              How many seconds to buffer log messages for (default: 0)
  --port=VALUE                    Port to listen on (default: 5050)
  --[no-]quiet                    Disable logging to stderr (default: false)
  --roles=VALUE                   A comma seperated list of the allocation
                                  roles that frameworks in this cluster may
                                  belong to.
  --[no-]root_submissions         Can root submit frameworks? (default: true)
  --slaves=VALUE                  Initial slaves that should be
                                  considered part of this cluster
                                  (or if using ZooKeeper a URL) (default: *)
  --user_sorter=VALUE             Policy to use for allocating resources
                                  between users. May be one of:
                                    dominant_resource_fairness (drf) (default: drf)
  --webui_dir=VALUE               Location of the webui files/assets (default: /usr/local/share/mesos/webui)
  --weights=VALUE                 A comma seperated list of role/weight pairs
                                  of the form 'role=weight,role=weight'. Weights
                                  are used to indicate forms of priority.
  --whitelist=VALUE               Path to a file with a list of slaves
                                  (one per line) to advertise offers for;
                                  should be of the form: file://path/to/file (default: *)
  --zk=VALUE                      ZooKeeper URL (used for leader election amongst masters)
                                  May be one of:
                                    zk://host1:port1,host2:port2,.../path
                                    zk://username:password@host1:port1,host2:port2,.../path
                                    file://path/to/file (where file contains one of the above) (default: )</pre>
    </div>

    <pre class="prettyprint lang-bsh">
$ mesos-slave --help</pre>

    <div class="solution">
      <pre>
Usage: mesos-slave [...]

Supported options:
  --attributes=VALUE                         Attributes of machine
  --[no-]checkpoint                          Whether to checkpoint slave and frameworks information
                                             to disk. This enables a restarted slave to recover
                                             status updates and reconnect with (--recover=reconnect) or
                                             kill (--recover=kill) old executors (default: false)
  --default_role=VALUE                       Any resources in the --resources flag that
                                             omit a role, as well as any resources that
                                             are not present in --resources but that are
                                             automatically detected, will be assigned to
                                             this role. (default: *)
  --disk_watch_interval=VALUE                Periodic time interval (e.g., 10secs, 2mins, etc)
                                             to check the disk usage (default: 1mins)
  --executor_registration_timeout=VALUE      Amount of time to wait for an executor
                                             to register with the slave before considering it hung and
                                             shutting it down (e.g., 60secs, 3mins, etc) (default: 1mins)
  --executor_shutdown_grace_period=VALUE     Amount of time to wait for an executor
                                             to shut down (e.g., 60secs, 3mins, etc) (default: 5secs)
  --frameworks_home=VALUE                    Directory prepended to relative executor URIs (default: )
  --gc_delay=VALUE                           Maximum amount of time to wait before cleaning up
                                             executor directories (e.g., 3days, 2weeks, etc).
                                             Note that this delay may be shorter depending on
                                             the available disk usage. (default: 1weeks)
  --hadoop_home=VALUE                        Where to find Hadoop installed (for
                                             fetching framework executors from HDFS)
                                             (no default, look for HADOOP_HOME in
                                             environment or find hadoop on PATH) (default: )
  --[no-]help                                Prints this help message (default: false)
  --ip=VALUE                                 IP address to listen on
  --isolation=VALUE                          Isolation mechanism, may be one of: process, cgroups (default: process)
  --launcher_dir=VALUE                       Location of Mesos binaries (default: /usr/local/libexec/mesos)
  --log_dir=VALUE                            Location to put log files (no default, nothing
                                             is written to disk unless specified;
                                             does not affect logging to stderr)
  --logbufsecs=VALUE                         How many seconds to buffer log messages for (default: 0)
  --master=VALUE                             May be one of:
                                               zk://host1:port1,host2:port2,.../path
                                               zk://username:password@host1:port1,host2:port2,.../path
                                               file://path/to/file (where file contains one of the above)
  --port=VALUE                               Port to listen on (default: 5051)
  --[no-]quiet                               Disable logging to stderr (default: false)
  --recover=VALUE                            Whether to recover status updates and reconnect with old executors.
                                             Valid values for 'recover' are
                                             reconnect: Reconnect with any old live executors.
                                             cleanup  : Kill any old live executors and exit.
                                                        Use this option when doing an incompatible slave
                                                        or executor upgrade!).
                                             NOTE: If checkpointed slave doesn't exist, no recovery is performed
                                                   and the slave registers with the master as a new slave. (default: reconnect)
  --resource_monitoring_interval=VALUE       Periodic time interval for monitoring executor
                                             resource usage (e.g., 10secs, 1min, etc) (default: 5secs)
  --resources=VALUE                          Total consumable resources per slave, in
                                             the form 'name(role):value;name(role):value...'.
  --[no-]strict                              If strict=true, any and all recovery errors are considered fatal.
                                             If strict=false, any expected errors (e.g., slave cannot recover
                                             information about an executor, because the slave died right before
                                             the executor registered.) during recovery are ignored and as much
                                             state as possible is recovered.
                                             (default: false)
  --[no-]switch_user                         Whether to run tasks as the user who
                                             submitted them rather than the user running
                                             the slave (requires setuid permission) (default: true)
  --work_dir=VALUE                           Where to place framework work directories
                                             (default: /tmp/mesos)</pre>
    </div>
  </li>
</ol>

<hr />

<h3 id="web-interface">Web Interface</h3>

<p>A web interface is available on the master. The default master port is
<code>5050</code> (which can be changed via the <code>--port</code> option). <em>Note that the
port used for the web interface <strong>is the same</strong> port used by the
slaves to connect to the master!</em></p>

<ol>
  <li>
    <p>Open your favorite browser and go to
<code>http://&lt;master_node_hostname&gt;:5050</code>:</p>

    <div class="solution">
      <p><img src="img/mesos-webui640.png" alt="Mesos Web UI" /></p>
    </div>
  </li>
  <li>
    <p>Without any frameworks running, the only thing interesting is the
connected slaves. Click <code>Slaves</code> in the top navigation bar:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-all-slaves640.png" alt="Mesos Web UI All Slaves" /></p>
    </div>
  </li>
</ol>

<p><strong>NOTE:</strong> <em>The web interface updates automagically so don&#8217;t bother
refreshing it or closing the window as we&#8217;ll use it throughout this
training.</em></p>

<hr />

<h3 id="high-availability">High Availability</h3>

<p>Multiple masters can be run simultaneously in order to provide high
availability (i.e., if one master fails, another will take over). The
current implementation relies on Apache ZooKeeper to perform leader
election between the masters. Slaves use ZooKeeper to find the leading
master as well. To start a master that uses ZooKeeper use the <code>--zk</code>
option:</p>

<pre>
--zk=VALUE                      ZooKeeper URL (used for leader election amongst masters)
                                May be one of:
                                  zk://host1:port1,host2:port2,.../path
                                  zk://username:password@host1:port1,host2:port2,.../path
                                  file://path/to/file (where file contains one of the above) (default: )</pre>

<p>To start a slave that uses ZooKeeper to determine the leading master
use the <code>--master</code> option:</p>

<pre>
--master=VALUE                             May be one of:
                                             zk://host1:port1,host2:port2,.../path
                                             zk://username:password@host1:port1,host2:port2,.../path
                                             file://path/to/file (where file contains one of the above)</pre>

<p><strong>NOTE:</strong> <em>Use</em> <code>file://</code> <em>when you want to use authentication (i.e.,</em>
<code>username:password</code><em>) but don&#8217;t want to reveal any secrets on the
command line (or in the environment)!</em></p>

<p>We&#8217;ve already launched a ZooKeeper cluster for you and started the
slaves with ZooKeeper. But let&#8217;s simulate a master failover!</p>

<ol>
  <li>
    <p>Kill the running master:</p>

    <pre class="prettyprint lang-bsh">
$ killall mesos-master</pre>

    <p>If you didn&#8217;t close your browser window, switch to it now:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-not-connected640.png" alt="Mesos Web UI Not Connected" /></p>
    </div>
  </li>
  <li>
    <p>Restart the master with the <code>--zk</code> option:</p>

    <pre class="prettyprint lang-bsh">
$ nohup mesos-master --zk=zk://master_node_hostname:2181/mesos &lt;/dev/null &gt;/dev/null 2&gt;&amp;1 &amp;</pre>

    <p>After the web interfaces refreshes you should see all of the slaves
re-registered.</p>
  </li>
</ol>

<p><strong>NOTE:</strong> <em>You can leverage the high availability of Mesos to perform
backwards compatible upgrades without any downtime!</em></p>

<hr />

<h3 id="logs">Logs</h3>

<p>By default, <em>a Mesos master and slave log to standard error</em>. You can
additionally log to the filesystem by setting the <code>--log_dir</code> option:</p>

<pre>
--log_dir=VALUE                 Location to put log files (no default, nothing
                                is written to disk unless specified;</pre>

<ol>
  <li>
    <p>Browse back to the &#8220;home&#8221; page (hit back or click <code>Mesos</code> in the
upper left corner) the to your browser and click on the <code>LOG</code> link in
the left hand column:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-no-log640.png" alt="Mesos Web UI No Log" /></p>
    </div>

    <p>Ah ha! Close the popup window and let&#8217;s restart the master using
the <code>--log_dir</code> option:</p>

    <pre class="prettyprint lang-bsh">
$ killall mesos-master
$ nohup mesos-master --zk=zk://master_node_hostname:2181/mesos --log_dir=/mnt/mesos-logs &lt;/dev/null &gt;/dev/null 2&gt;&amp;1 &amp;</pre>

    <p>Now click on the <code>LOG</code> link again:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-log640.png" alt="Mesos Web UI Log" /></p>
    </div>
  </li>
</ol>

<p><strong>NOTE:</strong> <em>The web interface is simply paging/tailing the logs from</em>
<code>/mnt/mesos-logs/mesos-master.INFO</code><em>, which you can do as well using</em>
<code>tail</code> <em>and/or</em> <code>less</code><em>.</em></p>

<hr />

<h3 id="rest-interface">REST Interface</h3>

<p>The Mesos masters and slaves provide a handful of REST endpoints that
can be useful for users and operators. A collection of &#8220;help&#8221; pages
are available for some of them (our version of <code>man</code> for REST).</p>

<ol>
  <li>
    <p>Go to <code>http://&lt;master_node_hostname&gt;:5050/help</code> in your browser to
see all of the available endpoints:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-help640.png" alt="Mesos Web UI Help" /></p>
    </div>
  </li>
  <li>
    <p>You can get more details about an endpoint or nested endpoints by
clicking on one; click on <code>/logging</code>:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-help-logging640.png" alt="Mesos Web UI Help Logging" /></p>
    </div>
  </li>
  <li>
    <p>Now click on <code>/logging/toggle</code> to see the help page:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-help-logging-toggle640.png" alt="Mesos Web UI Help Logging Toggle" /></p>
    </div>
  </li>
  <li>
    <p>Let&#8217;s toggle the verbosity level of the master:</p>

    <pre class="prettyprint lang-bsh">
$ curl 'http://master_node_hostname:5050/logging/toggle?level=3&amp;duration=1mins'</pre>

    <p>If you switch to (or reopen) the <code>LOG</code> popup window you should see
a lot more output now (but only for another minute!).</p>
  </li>
  <li>
    <p>The web interface uses the REST endpoints exclusively; for example,
to get the current &#8220;state&#8221; of a Mesos cluster (in JSON):</p>

    <pre class="prettyprint lang-bsh">
$ curl `http://master_node_hostname:5050/master/state.json` | python -mjson.tool</pre>

    <div class="solution">
      <pre class="prettyprint lang-js">
{
    "activated_slaves": 5,
    "build_date": "2013-08-26 06:41:22",
    "build_time": 1377499282,
    "build_user": "root",
    "completed_frameworks": [],
    "deactivated_slaves": 0,
    "failed_tasks": 0,
    "finished_tasks": 0,
    "frameworks": [],
    "id": "201308280103-3340478474-5050-8366",
    "killed_tasks": 0,
    "leader": "master@10.168.27.199:5050",
    "log_dir": "/mnt/mesos-logs",
    "lost_tasks": 0,
    "pid": "master@10.168.27.199:5050",
    "slaves": [
        {
            "attributes": {},
            "hostname": "ec2-54-226-160-180.compute-1.amazonaws.com",
            "id": "201308270519-3340478474-5050-5886-2",
            "pid": "slave(1)@10.235.1.38:5051",
            "registered_time": 1377651804.00701,
            "reregistered_time": 1377651804.00703,
            "resources": {
                "cpus": 4,
                "disk": 418176,
                "mem": 13960,
                "ports": "[31000-32000]"
            }
        },
        {
            "attributes": {},
            "hostname": "ec2-107-21-68-44.compute-1.amazonaws.com",
            "id": "201308270519-3340478474-5050-5886-0",
            "pid": "slave(1)@10.182.129.12:5051",
            "registered_time": 1377651804.00682,
            "reregistered_time": 1377651804.00682,
            "resources": {
                "cpus": 4,
                "disk": 418176,
                "mem": 13960,
                "ports": "[31000-32000]"
            }
        },
        {
            "attributes": {},
            "hostname": "ec2-54-227-64-244.compute-1.amazonaws.com",
            "id": "201308270519-3340478474-5050-5886-4",
            "pid": "slave(1)@10.235.48.134:5051",
            "registered_time": 1377651804.0065899,
            "reregistered_time": 1377651804.0065999,
            "resources": {
                "cpus": 4,
                "disk": 418176,
                "mem": 13960,
                "ports": "[31000-32000]"
            }
        },
        {
            "attributes": {},
            "hostname": "ec2-54-211-57-184.compute-1.amazonaws.com",
            "id": "201308270519-3340478474-5050-5886-1",
            "pid": "slave(1)@10.181.139.99:5051",
            "registered_time": 1377651804.00635,
            "reregistered_time": 1377651804.0063601,
            "resources": {
                "cpus": 4,
                "disk": 418176,
                "mem": 13960,
                "ports": "[31000-32000]"
            }
        },
        {
            "attributes": {},
            "hostname": "ec2-54-221-25-64.compute-1.amazonaws.com",
            "id": "201308270519-3340478474-5050-5886-3",
            "pid": "slave(1)@10.181.142.211:5051",
            "registered_time": 1377651804.0058999,
            "reregistered_time": 1377651804.0059199,
            "resources": {
                "cpus": 4,
                "disk": 418176,
                "mem": 13960,
                "ports": "[31000-32000]"
            }
        }
    ],
    "staged_tasks": 0,
    "start_time": 1377651801.08849,
    "started_tasks": 0,
    "version": "0.15.0"
}
</pre>
    </div>
  </li>
</ol>

<hr />

<h3 id="frameworks">Frameworks</h3>

<p>Mesos isn&#8217;t very useful unless you run some frameworks! We&#8217;ll now walk
through launching Hadoop and Spark on Mesos.</p>

<p>For now, it&#8217;s expected that you run framework schedulers independently
of Mesos itself. You can often reuse your master machine(s) for this
purpose (which is what we&#8217;ll do here).</p>

<h4 id="hadoop">Hadoop</h4>

<p>We downloaded a Hadoop distribution including support for Mesos
already. See
<a href="http://github.com/mesos/hadoop"><code>http://github.com/mesos/hadoop</code></a> for
more details on how to create/download a Hadoop distribution including
Mesos.</p>

<p>You <strong>DO NOT</strong> need to install Hadoop on every machine in your cluster
in order to run Hadoop on Mesos! Instead, you can upload your Hadoop
distribution to <code>HDFS</code> and configure the <code>JobTracker</code>
appropriately. We&#8217;ve already uploaded our distribution to <code>HDFS</code> as
well as configured the <code>JobTracker</code>. Take a look at
<code>/root/ephemeral-hdfs/conf/mapred-site.xml</code> for more details.</p>

<ol>
  <li>
    <p>Launch Hadoop (i.e., the <code>JobTracker</code>):</p>

    <pre class="prettyprint lang-bsh">
$ hadoop jobtracker &gt;/mnt/jobtracker.out 2&gt;&amp;1 &amp;</pre>

    <p>The web interface should show Hadoop under <code>Active Frameworks</code>:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-active-hadoop640.png" alt="Mesos Web UI Active Hadoop" /></p>
    </div>

    <p>Clicking on the link in the <code>ID</code> column for Hadoop takes you to a
page with task information (albeit, there are not currently any
tasks):</p>

    <div class="solution">
      <p><img src="img/mesos-webui-hadoop-no-tasks640.png" alt="Mesos Web UI Hadoop No Tasks" /></p>
    </div>
  </li>
  <li>
    <p>Launch a Hadoop job (calculating pi):</p>

    <pre class="prettyprint lang-bsh">
$ hadoop jar /root/ephemeral-hdfs/hadoop-examples-1.0.4.jar pi 4 1000</pre>

    <p>You should now see some tasks in the web interface:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-hadoop-tasks640.png" alt="Mesos Web UI Hadoop Tasks" /></p>
    </div>

    <p>Click on <code>Sandbox</code> on the far right column of one of the tasks:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-hadoop-sandbox640.png" alt="Mesos Web UI Hadoop Sandbox" /></p>
    </div>

    <p>Click on <code>stderr</code> to see the standard error of the <code>TaskTracker</code>:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-hadoop-stdout640.png" alt="Mesos Web UI Hadoop stdout" /></p>
    </div>
  </li>
</ol>

<h4 id="spark">Spark</h4>

<p>Like Hadoop, you need to upload a Spark &#8220;distribution&#8221; to
<code>HDFS</code>. We&#8217;ve already done this for you, but we&#8217;ll walk through the
steps here for completeness:</p>

<pre class="prettyprint lang-bsh">
$ cd spark
$ ./make_distribution.sh
$ mv dist spark-x.y.z
$ tar czf spark-x.y.z.tar.gz spark-x.y.z
$ hadoop fs -put spark-x.y.z.tar.gz /path/to/spark-x.y.z.tar.gz</pre>

<p>You&#8217;ll need to set the configuration property <code>spark.executor.uri</code> or
the environment variable <code>SPARK_EXECUTOR_URI</code> to
<code>/path/to/spark-x.y.z.tar.gz</code> in <code>HDFS</code>. We&#8217;ve set the environment
variable for you in <code>/root/spark/conf/spark-env.sh</code>.</p>

<ol>
  <li>
    <p>Start the Spark shell:</p>

    <pre class="prettyprint lang-bsh">
$ MASTER=mesos://master_node_hostname:5050 ./spark-shell</pre>

    <p>The web interface should show both Hadoop and Spark under <code>Active
Frameworks</code>:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-active-hadoop-and-spark640.png" alt="Mesos Web UI Active Hadoop and Spark" /></p>
    </div>
  </li>
  <li>
    <p>Let&#8217;s simulate an error that might occur if we forgot to upload the
Spark distribution (or forgot to set <code>SPARK_EXECUTOR_URI</code>). We&#8217;ll
do this by renaming the Spark distribution in <code>HDFS</code>:</p>

    <pre class="prettyprint lang-bsh">
$ hadoop fs -mv /spark.tar.gz /_spark.tar.gz</pre>
  </li>
  <li>
    <p>Run a simple Spark query:</p>

    <div class="codetabs">
  <div data-lang="scala">
        <pre><code>scala&gt; sc
res: spark.SparkContext = spark.SparkContext@470d1f30

scala&gt; val pagecounts = sc.textFile("/wiki/pagecounts")
12/08/17 23:35:14 INFO mapred.FileInputFormat: Total input paths to process : 74
pagecounts: spark.RDD[String] = MappedRDD[1] at textFile at &lt;console&gt;:12
scala&gt; pagecounts.count
</code></pre>
      </div>
  <div data-lang="python">
        <pre><code>&gt;&gt;&gt; sc
&lt;pyspark.context.SparkContext object at 0x7f7570783350&gt;
&gt;&gt;&gt; pagecounts = sc.textFile("/wiki/pagecounts")
13/02/01 05:30:43 INFO mapred.FileInputFormat: Total input paths to process : 74
&gt;&gt;&gt; pagecounts
&lt;pyspark.rdd.RDD object at 0x217d510&gt;
&gt;&gt;&gt; pagecounts.count()
</code></pre>
      </div>
</div>

    <p>You should start seeing tasks failing (<code>State</code> is <code>LOST</code>):</p>

    <div class="solution">
      <p><img src="img/mesos-webui-spark-tasks-lost640.png" alt="Mesos Web UI Spark Tasks Lost" /></p>
    </div>

    <p>Click on the <code>Sandbox</code> of any lost task and open up <code>stdout</code>:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-spark-lost-task-stdout640.png" alt="Mesos Web UI Spark Lost Task Stdout" /></p>
    </div>

    <p>Okay, looks like we ran <code>hadoop</code> to fetch <code>spark.tar.gz</code>. Now click
on <code>stderr</code>:</p>

    <div class="solution">
      <p><img src="img/mesos-webui-spark-lost-task-stderr640.png" alt="Mesos Web UI Spark Lost Task Stderr" /></p>
    </div>

    <p>Ah ha! The slave failed to fetch the executor. Okay, exit the Spark
shell and let&#8217;s revert our rename of the Spark distribution:</p>

    <pre class="prettyprint lang-bsh">
$ hadoop fs -mv /_spark.tar.gz /spark.tar.gz</pre>

    <p>Now relaunch the Spark shell and reissue the query:</p>

    <div class="solution">
      <pre><code>res: Long = 329641466
</code></pre>
    </div>
  </li>
</ol>

<hr />

<p>All done! Hopefully this training gave you some basic knowledge of
using Mesos and some places to look for help. Please see the
<a href="http://github.com/apache/mesos/docs">github.com/apache/mesos/docs</a>
for more documentation. And don&#8217;t hesitate to email
user@mesos.apache.org with questions!</p>

        </div> <!-- /container -->
        <div class="bar bottombar">
            
<a class="btn page-nav" disabled="disable" style="float:left">

  <i class="icon-arrow-left icon-2x"></i>
</a>

            
<a class="btn page-nav" disabled="disable" style="float:right" href="#">

  <i class="icon-arrow-right icon-2x"></i>
</a>

            <div class="btn-group dropup">
                <div class="btn btn-large dropdown-toggle" data-toggle="dropdown">
                    Mesos - Cluster & Framework Mgmt &nbsp; <i class="icon-list-ul icon"></i>
                </div>
                <ul class="dropdown-menu" role="menu" aria-labelledby="dropdownMenu">
                    <ul class="dropdown-menu" role="menu" aria-labelledby="dropdownMenu">


  <li>
    
      
    
    <a href="/index.html">Introduction</a>
  </li>

  <li>
    
      
    
    <a href="/logging-into-the-cluster.html">Logging into the Cluster</a>
  </li>

  <li>
    
      
    
    <a href="/overview-of-the-exercises.html">Overview Of The Exercises</a>
  </li>

  <li>
    
      
    
    <a href="/introduction-to-the-scala-shell.html">Introduction to the Scala Shell</a>
  </li>

  <li>
    
      
      
    
    <a href="/data-exploration-using-spark.html">  1. Data Exploration Using Spark</a>
  </li>

  <li>
    
      
      
    
    <a href="/data-exploration-using-shark.html">  2. Data Exploration Using Shark</a>
  </li>

  <li>
    
      
      
    
    <a href="/realtime-processing-with-spark-streaming.html">  3. Stream Processing w/ Spark Streaming</a>
  </li>

  <li>
    
      
      
    
    <a href="/blinkdb.html">  4. Data Exploration Using BlinkDB</a>
  </li>

  <li>
    
      
      
    
    <a href="/mli-document-categorization.html">  5. Machine Learning With MLI</a>
  </li>

  <li>
    
      
      
    
    <a href="/mesos.html">  6. Mesos - Cluster & Framework Mgmt</a>
  </li>

  <li>
    
      
    
    <a href="/where-to-go-from-here.html">Where to Go From Here</a>
  </li>

</ul>
                </ul>
            </div>
            <div class="btn-group dropup">
              <a class="btn btn-large" target="_blank" href="https://github.com/amplab/training/issues">
                <i class="icon-exclamation-sign"> </i>
                Submit an issue on GitHub
              </a>
            </div>
            <div class="site-title">AMP Camp 3 Exercises Dry-Run</div>
        </div>

        <script src="js/vendor/jquery-1.8.3.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <!-- Table of contents plugin -->
        <script src="js/vendor/toc.js" type="text/javascript"></script>
        <script src="js/main.js"></script>
    </body>
</html>
